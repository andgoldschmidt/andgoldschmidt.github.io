[{"authors":null,"categories":null,"content":"Andy is a Physics PhD student working on quantum optimal control as an NSF QISE-NET fellow in collaboration with Lawrence Livermore National Laboratory. He also worked with the Pacific Northwest Research Institute on the inverse design of better commerical brewing and baking yeasts. Andy enjoys highly-collaborative environments and likes to seek out out ways to turn new scientific discoveries into practical applications using data-driven methods. Andy is advised by J. Nathan Kutz.\nEven though he is attached to the Applied Math Department, Lawrence Livermore National Laboratory, and the Pacific Northwest Research Institute, Andy remains an active part of the University of Washington Department of Physics. He has organized two iteratons (2018, 2019) of a multi-day networking event for the Physics Graduate School with invited industry sponsors, speakers, and alumni guests. Andy is also an officer of the Union Bay Rowing Club at the University of Washington and plays for Jet City F.C. in the Greater Seattle Soccer League. Andy is pictured here with his dog, Susie.\n  Download my C.V.\n","date":1616371200,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1616371200,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"","publishdate":"0001-01-01T00:00:00Z","relpermalink":"","section":"authors","summary":"Andy is a Physics PhD student working on quantum optimal control as an NSF QISE-NET fellow in collaboration with Lawrence Livermore National Laboratory. He also worked with the Pacific Northwest Research Institute on the inverse design of better commerical brewing and baking yeasts.","tags":null,"title":"Andy J. Goldschmidt","type":"authors"},{"authors":[],"categories":null,"content":"","date":1647444240,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1647444240,"objectID":"184d3e0eb4775b515aeca510088f41dd","permalink":"https://andgoldschmidt.github.io/talks/2022_03_mm/","publishdate":"2022-01-26T00:00:00Z","relpermalink":"/talks/2022_03_mm/","section":"talks","summary":"Model predictive control for robust quantum state preparation","tags":[],"title":"Invited talk, APS March Meeting","type":"talks"},{"authors":null,"categories":null,"content":"JAX is a research project from Google. For our purpose, JAX is a way to do automatic differentiation: With its updated version of Autograd, JAX can automatically differentiate native Python and NumPy functions. It can differentiate through loops, branches, recursion, and closures, and it can take derivatives of derivatives of derivatives. Numerical integration schemes are just native python and NumPy functions so JAX can automatically differentiate them. An example of when we might want to automatically differentiating numerical integrators is the control of nonlinear dynamical systems.\nIn particular, the purpose of this post is to learn how to do three things.\n Use JAX. Implement a few numerical integration schemes. Use JAX to linearize a numerical integration scheme.  import jax.numpy as jnp from jax import grad, jit, vmap, jacfwd, jacrev import numpy as np from tqdm.notebook import tqdm, trange  import matplotlib.pyplot as plt from matplotlib.cm import ScalarMappable  Derivatives with JAX  JAX can compute derivatives through algorithms. A nice introduction is: https://www.assemblyai.com/blog/why-you-should-or-shouldnt-be-using-jax-in-2022/\nHere is a function, the rectified cube: \\begin{equation} f(x) = |x|^3. \\end{equation}\nWe can define $f(x)$ in a bit of a silly way by using an if statement.\ndef rectified_cube(x): r = 1 if x \u0026lt; 0.: for i in range(3): r *= x r = -r else: for i in range(3): r *= x return r  JAX can differentiate this $f(x)$ no problem.\ngradient_function = grad(rectified_cube)  fig, ax = plt.subplots(1) xs = np.linspace(-1, 1) fx = [] d_fx = [] for x in xs: fx.append(rectified_cube(x)) d_fx.append(gradient_function(x)) ax.plot(xs, fx, xs, d_fx, lw=2) ax.legend(['$|x|^3$', '$\\\\frac{d}{dx} |x|^3$'], fontsize=14, ncol=2) ax.set_xlabel('x', fontsize=14);     Numerical integration + Autodiff  Here is a continuous model: \\begin{equation} \\dot{x}(t) = f(x(t), u(t)). \\end{equation}\nIn many situations in computing (like model predictive control), the continuous dynamics must be converted to a discrete model \\begin{equation} x_{k + 1} = F(x_k, u_k). \\end{equation}\nThe reason for the conversion is that controls are computed as a zero-order-hold over discrete time intervals. The full discrete list of control amplitudes can be optimized. In the continuous limit, the discrete list becomes a function. Working with functions is much harder and doesn\u0026rsquo;t allow for a scheme like MPC which depends on taking a step. Plus, you can often use a simple basis to approximate function dynamics within the discrete time step (how?).\nThe RHS term $F(x_k, u_k)$ is a numerical integration. There are many ways to do this. $F$ is frequently nonlinear. Unfortunately, we really only know how to do MPC for systems with linear discrete dynamics where \\begin{equation} F(x_k, u_k)=A x_k + B u_k. \\end{equation} In order to do more interesting systems, we rely on locally linear approximations of $F$ in algorithms. This means the model is local about some guess trajectory, i.e. you compute matrices like \\begin{equation} A \\equiv \\nabla_x F(x, u)|_{x_g} \\end{equation} and multiply them with $x - x_g$ (it\u0026rsquo;s just the 1st order Fourier expansion). In MPC, the choice for $x_g$ (read: x-guess) is often a recently valid solution that\u0026rsquo;s been shifted to the left to accommodate the next prediction horizon. In any case, this means we want derivatives of $F$. This is where JAX comes in: If we know the continuous model $f$ and the algorithm $A$ we used to compute the numerical integration (i.e. $F = A \\circ f$), we can find these linear approximations with automatic differentiaton.\nWhy might this be better? It\u0026rsquo;s hard (or at a minumum, annoying) to compute an analytic linearization of some numerical integrators $F$ even for simple nonlinear dynamics.\nExercise: Are there cases where it might not be reasonable to explicitely compute derivatives?\nVan der Pol experiment In this section, we\u0026rsquo;ll review some numerical integrators as preparation for thinking about how we might locally linearize them with JAX.\nThe toy system we will use is a driven Van der Pol oscillator, \\begin{equation} \\begin{aligned} \u0026amp;\\dot{x}_1 = x_2, \\\n\u0026amp;\\dot{x}_2 = -x_1 + \\mu (1 - x_1^2) x_2 + u \\end{aligned} \\end{equation}\ndef vdp(t, x, u): mu = 2 x1, x2 = x return jnp.array([ x2, -x1 + mu * (1 - x1 ** 2) * x2 + u ])  Euler integration The simplest choice for numerical integration is Euler integration, which combines the definition of the derivative \\begin{equation} \\dot{x}(t) = \\lim_{\\Delta t \\rightarrow 0} \\frac{\\Delta x}{\\Delta t} \\end{equation} with the dynamics $\\dot{x}(t) = f(t, x(t), u(t))$ such that \\begin{equation} \\frac{x_{k+1} - x_k}{\\Delta t} \\approx f(k, x_k, u_k) \\end{equation} so \\begin{equation} x_{k+1} \\approx x_k + \\Delta t f(k, x_k, u_k) \\equiv F(x_k, u_k) \\end{equation}\nSet $z_k = [x_k, u_k]$ for simplicity.\ndef euler(z, dt=1): return z[:2] + dt * vdp(_, z[:2], z[2])  # Driving is external; set a policy. def u_fn(t): return jnp.zeros_like(t)  One fun thing to do is break the numerical integration by taking steps that are too big. Do that by dividing the interval [0,15] into 100 steps.\n# Simulate the oscillator. ts = jnp.linspace(0, 15, 100) dt = ts[1] - ts[0] t0 = ts[0] x0 = jnp.array([[1], [-2]]) xs = [None] * (len(ts) + 1) xs[0] = x0 for i, t in tqdm(enumerate(ts), total=len(ts)): z = jnp.vstack([xs[i], u_fn(t)]) xs[i + 1] = euler(z, dt) xs = jnp.hstack(xs)  x1, x2 = xs fig, ax = plt.subplots(1, figsize=[8,8]) ax.plot(x1, x2, lw=5) ax.set_aspect('equal')     We can compute the Jacobian of $F(x_k, u_k)$ using JAX. That is, we want to compute the derivative to arrive at a matrix, $\\nabla_z F(z)$. There are a few ways to do this with JAX.\n# Differentiate (retain ability to use other args) jac_euler = jacfwd(euler) # Is prefixing values faster? Not by much. jac_euler_2 = jacfwd(lambda z: euler(z, dt)) # Is backward faster? No way! Recall: Why not? jac_euler_3 = jacrev(euler)  jac_xs = [None] * len(ts) det_jac_xs = [None] * len(ts) for i, t in tqdm(enumerate(ts), total=len(ts)): z = jnp.vstack([xs[:, i][:, None], u_fn(t)]) jac_xs[i] = jac_euler(z.squeeze(), dt) det_jac_xs[i] = np.linalg.det(jac_xs[i][:, :2])  $\\nabla_z F(z)$ is a matrix. Our goal in a first order linearization is to compute something like $\\Delta F = \\nabla_z F(z) \\cdot \\Delta z$. Here, let\u0026rsquo;s do that for the $x$ values.\n# Find the differential of F dx = xs[:, 1:] - xs[:, :-1] df = np.vstack([jac_xs[i][:,:2] @ dx[:, i] for i in range(len(ts))]).T  Notice that the derivatives are only as good as our numerical integration (which we already decided to break). Keep in mind that this is the behavior you would get even if you did analytic derivatives with respect to the Euler integration scheme.\n# Plot tangent vectors colored by the determinant of the Jacobian fig, ax = plt.subplots(1, figsize=[8, 8]) cmap = plt.get_cmap('viridis') norm = plt.Normalize(min(det_jac_xs), max(det_jac_xs)) for i in range(len(ts)): ax.arrow(x1[i], x2[i], df[0][i], df[1][i], width=.05, color=cmap(norm(det_jac_xs[i]))) ax.set_aspect('equal') fig.colorbar(ScalarMappable(norm=norm, cmap=cmap))     If you want to peak at the matrix assoicated to $\\nabla_z F(z)$, then you need to act on basis vectors.\nbasis = [None] * (xs.shape[0] + 1) for i in range(len(basis)): basis[i] = np.zeros([xs.shape[0] + 1, 1]) basis[i][i] = 1 z0 = jnp.vstack([xs[:, 0][:, None], u_fn(t)]) np.hstack([jac_euler(z0.squeeze(), dt) @ b for b in basis])  array([[1. , 0.15151516, 0. ], [1.0606061 , 1. , 0.15151516]], dtype=float32)  Runge-Kutta methods One nice thing with JAX is that if we pick more interesting numerical integration schemes, we don\u0026rsquo;t have to worry about computing the analytic derivative of the more complicated function $F(x_k, u_k)$. Let\u0026rsquo;s see this in action.\nGeneralize the Euler method so that \\begin{equation} x_{k+1} \\approx x_k + \\Delta t \\phi(k, x_k, u_k) \\equiv F(x_k, u_k) \\end{equation} with $\\phi$ some new function defined to reduce errors by leveraging intermediate evaluations of $f$.\nI\u0026rsquo;m not going to derive it, but one way to improve things is the classic 4th order Runge-Kutta:\n\\begin{equation} x_{k+1} \\approx x_k + \\frac{\\Delta t}{6} (f_1 + 2 f_2 + 2 f_3 + f_4) \\end{equation} where\n$f_1 = f(t_k, x_k, u_k)$,\n$f_2 = f(t_k + \\Delta t / 2, x_k + f_1 \\Delta t / 2, u_k)$,\n$f_3 = f(t_k + \\Delta t / 2, x_k + f_2 \\Delta t / 2, u_k)$,\n$f_4 = f(t_k + \\Delta t, x_k + f_3 \\Delta t, u_k)$.\nWhy do we modify the $x$ arguments in the function, but not the $u$ arguments? First off, we assume $f$ is a known function, but we don\u0026rsquo;t know anything about the control policy. Our control assumption is actually zero-order-hold so we are assuming $u_k$ won\u0026rsquo;t vary within our step. This is pretty important for the validity of the scheme. Luckily we\u0026rsquo;re in charge of the control so we can set this.\nFor completeness, let\u0026rsquo;s just say we don\u0026rsquo;t make the assumption of zero order hold. Then the Runge-Kutta approximation is not going to satisfy the promised accuracy, and we don\u0026rsquo;t have any way to improve the integration by cancelling Fourier terms like we did with $x$ (this is because $u$ is not constrained by a function). One final way to think about this: if we did know the policy, then $f(t, x, u) \\mapsto f(t, x, \\pi(t, x)) \\equiv f^\\pi(t, x)$ and we can have no gradients with respect to $u$ because it is fixed by the policy.\n# Again, we don't have explicit time dependence. # Exercise: How would things change? def rk4(z, dt=1): f1 = vdp(_, z[:2], z[2]) f2 = vdp(_, z[:2] + f1 * dt / 2, z[2]) f3 = vdp(_, z[:2] + f2 * dt / 2, z[2]) f4 = vdp(_, z[:2] + f3 * dt, z[2]) return z[:2] + (f1 + 2 * f2 + 2 * f3 + f4) * dt / 6  Pick the same time scheme as before, but now we\u0026rsquo;re going to get a much better numerical integration with our improved method.\n# Simulate the oscillator. xs = [None] * (len(ts) + 1) xs[0] = x0 for i, t in tqdm(enumerate(ts), total=len(ts)): z = jnp.vstack([xs[i], u_fn(t)]) xs[i + 1] = rk4(z, dt) xs = jnp.hstack(xs)  x1, x2 = xs fig, ax = plt.subplots(1, figsize=[8,8]) ax.plot(x1, x2, lw=5) ax.set_aspect('equal')     Repeat the same differentiation process using JAX to get improved derivatives inherited directly from the improved numerical integration.\n# Differentiate jac_rk4 = jacfwd(rk4)  jac_xs = [None] * len(ts) det_jac_xs = [None] * len(ts) for i, t in tqdm(enumerate(ts), total=len(ts)): z = jnp.vstack([xs[:, i][:, None], u_fn(t)]) jac_xs[i] = jac_rk4(z.squeeze(), dt) det_jac_xs[i] = np.linalg.det(jac_xs[i][:, :2])   0%| | 0/100 [00:00\u0026lt;?, ?it/s]  # Find the differential of F dx = xs[:, 1:] - xs[:, :-1] df = np.vstack([jac_xs[i][:,:2] @ dx[:, i] for i in range(len(ts))]).T  # Plot tangent vectors colored by the determinant of the Jacobian fig, ax = plt.subplots(1, figsize=[8, 8]) cmap = plt.get_cmap('viridis') norm = plt.Normalize(min(det_jac_xs), max(det_jac_xs)) for i in range(len(ts)): ax.arrow(x1[i], x2[i], df[0][i], df[1][i], width=.05, color=cmap(norm(det_jac_xs[i]))) ax.set_aspect('equal') fig.colorbar(ScalarMappable(norm=norm, cmap=cmap))     Nice derivatives.\n","date":1646784000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1646784000,"objectID":"47884fef6a6d404db6d40f2cea2141e2","permalink":"https://andgoldschmidt.github.io/posts/jax_mpc/","publishdate":"2022-03-09T00:00:00Z","relpermalink":"/posts/jax_mpc/","section":"posts","summary":"A case study in combining automatic differentiation with numerical integration for applications like model predictive control.","tags":["Control"],"title":"Automatically differentiating numerical integrators","type":"posts"},{"authors":null,"categories":null,"content":"Helper functions for spectral DMD. # MIT License # Copyright (c) 2022 Andy Goldschmidt # Permission is hereby granted, free of charge, to any person obtaining a copy # of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal # in the Software without restriction, including without limitation the rights # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell # copies of the Software, and to permit persons to whom the Software is # furnished to do so, subject to the following conditions: # The above copyright notice and this permission notice shall be included in all # copies or substantial portions of the Software. # THE SOFTWARE IS PROVIDED \u0026quot;AS IS\u0026quot;, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR # IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, # FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE # AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER # LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, # OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE # SOFTWARE. import numpy as np def BigOmg(omega, ts): ''' Construct time-domain coordinates for Spectral DMD. Args: omega (`1d-array`): 1d array of frequencies ts (`1d-arary`): 1d array of times Returns: `nd-array`: 2*len(omega) by len(t) array of $[\\cos(\\vec{omega} t), \\sin(\\vec{omega} t)]^T$ ''' omt = omega.reshape(-1,1)@ts.reshape(1,-1) return np.vstack([np.cos(2*np.pi*omt), np.sin(2*np.pi*omt)]) def loss(X, A, omega, ts): ''' Loss function for Spectral DMD. Returns: float: Evaluation of loss function. ''' return np.linalg.norm(X - A@BigOmg(omega,ts)) def grad_loss(X, A, omega, ts): ''' Gradient of the loss function w.r.t. $\\omega$. ''' n_omg = len(omega) part2 = -4*np.pi*A.T@(X - A@BigOmg(omega,ts)) grad_res = [0]*n_omg for i in range(n_omg): grad_res[i] += (-np.sin(2*np.pi*omega[i]*ts)*ts).dot(part2[i,:]) grad_res[i] += (np.cos(2*np.pi*omega[i]*ts)*ts).dot(part2[n_omg + i,:]) return np.array(grad_res).reshape(1,-1) def grad_loss_j(j, X, A, omega, ts): ''' Gradient of the loss function w.r.t. $\\omega_j$ Returns: float: Gradient of the loss w.r.t $\\omega_j$ ''' n_omg = len(omega) if j \u0026gt; n_omg - 1: raise ValueError(\u0026quot;Invalid value. Index j={} exceeds len(omega)={}.\u0026quot;.format(j,n_omg)) part2 = -4*np.pi*A.T@(X - A@BigOmg(omega,ts)) grad_res_j = (-np.sin(2*np.pi*omega[j]*ts)*ts).dot(part2[j,:]) grad_res_j += (np.cos(2*np.pi*omega[j]*ts)*ts).dot(part2[n_omg + j,:]) return grad_res_j def residual_j(j, X, A, omega, ts): ''' Residual for the data trajectory X using the model A, $\\Omega$. The residual excludes the contribution of the frequency $\\omega_j$. TODO: * Check the case where A.shape[0] = 1 Returns: `ndarray`: residual of shape X.shape[0] by ts.shape[0] ''' n_omega = len(omega) if j \u0026gt; n_omega - 1: raise ValueError(\u0026quot;Invalid value. Index j={} exceeds len(omega)={}.\u0026quot;.format(j, n_omega)) j2 = j + n_omega indices = np.hstack([np.arange(j), np.arange(j+1,j2), np.arange(j2+1, 2*n_omega)]) return X - A[:,indices]@(BigOmg(omega,ts)[indices, :]) def update_A(X, omega, ts, threshold, threshold_type): # Update A # -- This step could get some DMD love U,S,Vt = np.linalg.svd(BigOmg(omega, ts), full_matrices=False) if threshold_type == 'count': r = threshold elif threshold_type == 'percent': r = np.sum(S/np.max(S) \u0026gt; threshold) rU = U[:,:r] rS = S[:r] rVt = Vt[:r, :] return X@np.conj(rVt.T)@np.diag(1/rS)@np.conj(rU.T) def max_fft_update(result, dt): # Real signal means the other half of the hat are complex conjugates n = result.shape[1] n_sym = n//2 if n % 2 == 0 else n//2 + 1 # Compute fft res_hat = np.fft.fft(result, axis=1) # Get the maximum freq. coordinate considering all data dimensions ires = np.argmax(np.sum(np.abs(res_hat[:,:n_sym]), axis=0)) res_freq = np.fft.fftfreq(n, dt)[:n_sym] return res_freq[ires] # Accelerated proximal gradient descent # ----------------------------------------------------------------------------- def optimizeWithAPGD(x0, func_f, func_g, grad_f, prox_g, beta_f, tol=1e-6, max_iter=1000, verbose=False): \u0026quot;\u0026quot;\u0026quot; Optimize with Accelerated Proximal Gradient Descent Method min_x f(x) + g(x) where f is beta smooth and g is proxiable. input ----- x0 : array_like Starting point for the solver func_f : function Input x and return the function value of f func_g : function Input x and return the function value of g grad_f : function Input x and return the gradient of f prox_g : function Input x and a constant float number and return the prox solution beta_f : float beta smoothness constant for f tol : float, optional Gradient tolerance for terminating the solver. max_iter : int, optional Maximum number of iteration for terminating the solver. output ------ x : array_like Final solution obj_his : array_like Objective function value convergence history err_his : array_like Norm of gradient convergence history exit_flag : int 0, norm of gradient below `tol` 1, exceed maximum number of iteration 2, others \u0026quot;\u0026quot;\u0026quot; # initial information x = x0.copy() y = x0.copy() g = grad_f(y) t = 1.0 # step_size = 1.0/beta_f # not recording the initial point since we do not have measure of the optimality obj_his = np.zeros(max_iter) err_his = np.zeros(max_iter) # start iteration iter_count = 0 err = tol + 1.0 while err \u0026gt;= tol: ##### # Accelerated proximal gradient x_new = prox_g(y - step_size*g, step_size) t_new = (iter_count - 1)/(iter_count + 2) y_new = x_new + t_new*(x_new - x) # FISTA version: # t_new = (1 + np.sqrt(1+4*t**2))/2 # y_new = x_new + (t - 1)/t_new*(x_new - x) ##### # # update information obj = func_f(x_new) + func_g(x_new) err = np.linalg.norm(x - x_new) # np.copyto(x, x_new) np.copyto(y, y_new) t = t_new g = grad_f(y) # obj_his[iter_count] = obj err_his[iter_count] = err # # check if exceed maximum number of iteration iter_count += 1 if iter_count \u0026gt;= max_iter: if verbose: print('Proximal gradient descent reach maximum of iteration') return x, obj_his[:iter_count], err_his[:iter_count], 1 # return x, obj_his[:iter_count], err_his[:iter_count], 0  ","date":1641254400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641254400,"objectID":"98d557db8f06ea677ae37719a2998d28","permalink":"https://andgoldschmidt.github.io/pages/spectral_help/","publishdate":"2022-01-04T00:00:00Z","relpermalink":"/pages/spectral_help/","section":"pages","summary":"Helper functions for spectral DMD. # MIT License # Copyright (c) 2022 Andy Goldschmidt # Permission is hereby granted, free of charge, to any person obtaining a copy # of this software and associated documentation files (the \u0026quot;Software\u0026quot;), to deal # in the Software without restriction, including without limitation the rights # to use, copy, modify, merge, publish, distribute, sublicense, and/or sell # copies of the Software, and to permit persons to whom the Software is # furnished to do so, subject to the following conditions: # The above copyright notice and this permission notice shall be included in all # copies or substantial portions of the Software.","tags":null,"title":"","type":"pages"},{"authors":[],"categories":null,"content":"","date":1632614400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1632614400,"objectID":"7d94930f98409827f0d152b0423354f8","permalink":"https://andgoldschmidt.github.io/talks/2021_09_mmldtcset/","publishdate":"2021-09-26T00:00:00Z","relpermalink":"/talks/2021_09_mmldtcset/","section":"talks","summary":"Bilinear Dynamic Mode Decomposition for Quantum Control","tags":[],"title":"Invited talk, MMLDT-CSET","type":"talks"},{"authors":["Andy J. Goldschmidt","E. Kaiser","J.L. DuBois","S.L. Brunton","J.N. Kutz"],"categories":null,"content":" Click the Cite button above to demo the feature to enable visitors to import publication metadata into their reference management software.   --  Create your slides in Markdown - click the Slides button to check out the example.   -- Caption for the figure: The trajectory of a qubit driven by a linearly-polarized semi-classical drive $\\textrm{u}(t)$ (Hamiltonian: $H(t) = \\pi \\sigma_z + \\textrm{u}(t) \\sigma_x$) is shown on the Bloch sphere in (a). The corresponding Pauli-spin measurements are shown in (b). Measurements $\\mathbf{x}_j$, $j=1,2,\\dots$, are taken at discrete time steps and assembled into offset snapshot matrices $\\mathbf{X}$ and $\\mathbf{X}'$ in (c). The bilinear Dynamic Mode Decomposition (d) is a regression-based algorithm that uses the assembled data matrices and control input from sufficiently-resolved data to learn the intrinsic dynamics, $\\mathbf{A}$ and the control, $\\mathbf{B}$, for the bilinear dynamics.\n","date":1616371200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1616371200,"objectID":"883fe5b5c304c19f799e63d2fea508db","permalink":"https://andgoldschmidt.github.io/publication/bidmd/","publishdate":"2021-03-22T00:00:00Z","relpermalink":"/publication/bidmd/","section":"publication","summary":"We develop a data-driven regression procedure, _bilinear dynamic mode decomposition_ (biDMD), that leverages time-series measurements to establish quantum system identification for quantum optimal control.","tags":[],"title":"Bilinear dynamic mode decomposition for quantum control","type":"publication"},{"authors":[],"categories":null,"content":"Session 1     9:45-10:00 Calibrating Quantum Hardware with Online Optimal Control abstract   Jonathan L. Dubois, Lawrence Livermore National Laboratory, U.S.   10:05-10:20 Bilinear Dynamic Mode Decomposition for Quantum Control abstract   Andy Goldschmidt and Eurika Kaiser, University of Washington, U.S.; Jonathan L. Dubois, Lawrence Livermore National Laboratory, U.S.; Steve Brunton, University of Washington, U.S.; J. Nathan Kutz, University of Washington, Seattle, U.S.   10:25-10:40 Designing High-Fidelity Controls on Real Quantum Systems using\u0026nbsp;System\u0026nbsp;Identification and Reinforcement Learning abstract   Michael J. Biercuk, University of Sydney, Australia; Harrison Ball, Q-CTRL, Australia; Yuval Baum, California Institute of Technology, U.S.; Andre Carvalho, Griffith University, Brisbane, Australia; Leonardo de Castro, Sean Howell, Michael Hush, and Per Liebermann, Q-CTRL, Australia; Pranav Mundada, Princeton University, U.S.; Felix Thomsen, Q-CTRL, Australia   10:45-11:00 Quantum System Compression: A Hamiltonian Guided Walk through Hilbert Space abstract   Robert L. Kosut, SC Solutions, U.S.; Herschel Rabitz and Tak-San Ho, Princeton University, U.S.   11:05-11:20 Learning the States of Quantum Dot Systems: A Ray-Based Framework abstract   Justyna Zwolak, National Institute of Standards and Technology, U.S.   Session 2     2:15-2:30 A General Theory of Randomized Benchmarking abstract   Jens Eisert, Freie Universität Berlin, Germany; Jonas Helsen, University of Amsterdam, Netherlands; Ingo Roth, Freie Universität Berlin, Germany; Emilio Onorati, University College London, United Kingdom; Albert H. Werner, University of Copenhagen, Denmark   2:35-2:50 Operational, Gauge-Free Quantum Tomography abstract   Olivia Di Matteo, TRIUMF, Canada; John Gamble and Chris Granade, Microsoft Research, U.S.; Kenneth Rudinger, Sandia National Laboratories, U.S.; Nathan O. Wiebe, University of Washington, U.S.   2:55-3:10 Linear Preservers on Infinitely Divisible Matrices through Separability abstract   Indu L and Jill K Mathew, Mar Ivanios College, Trivandrum, Kerala, India   3:15-3:30 Machine Learning for Quantum States abstract   Giuseppe Carleo, EPFL, Switzerland   3:35-3:50 Learning Models of Quantum Systems from Experiments abstract  Antonio Gentile and Brian Flynn, University of Bristol, United Kingdom; Sebastian Knauer, University of Vienna, Austria;  Nathan O. Wiebe, University of Washington, U.S.; Stefano Paesani, University of Bristol, United Kingdom; Chris Granade, Microsoft Research, U.S.; John Rarity, Raffaele Santagati, and Anthony Laing, University of Bristol, United Kingdom   ","date":1614600000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1614600000,"objectID":"2238d7ebe3cb8bf5ccf95e306cbf4c79","permalink":"https://andgoldschmidt.github.io/talks/2021_03_siamcse/","publishdate":"2021-03-01T00:00:00Z","relpermalink":"/talks/2021_03_siamcse/","section":"talks","summary":"Data-Driven Methods for Quantum Dynamics and Control","tags":[],"title":"Minisymposium organizer, SIAM CSE","type":"talks"},{"authors":null,"categories":null,"content":"Spectral dynamic mode decomposition is my term for Algorithm 1 from the paper From Fourier to Koopman: Spectral Methods for Long-term Time Series Prediction by H. Lange, S.L. Brunton, J.N. Kutz (video) (arXiv). Necessary background is a familiarity with the dynamic mode decomposition (video) (Wikipedia entry).\nThis project walks through a toy example I coded up in Python. The example is similar to one from the paper which gets across the main points. I have packed away the main functions for the algorithm in the utility spectral_help.py which has been linked in this project\u0026rsquo;s description.\nimport numpy as np from numpy.linalg import norm, solve import matplotlib.pyplot as plt cmap = plt.get_cmap('tab20') from spectral_help import *  Example Definition class toy_data: \u0026quot;\u0026quot;\u0026quot; Generate toy oscillation data at specific frequencies. \u0026quot;\u0026quot;\u0026quot; def __init__(self, tf, npts, noise): \u0026quot;\u0026quot;\u0026quot; Parameters: tf: final time npts: number of samples between 0 and tf noise: standard deviation of additive Gaussian noise \u0026quot;\u0026quot;\u0026quot; self.tf = tf self.npts = npts self.ts = np.linspace(0, self.tf, self.npts) self.dt = self.ts[1] - self.ts[0] self.noise = noise # Manual toy data (a stack of sines) self.freqs = [0.5, 2, 0.75, 3] self.X_fn = lambda ts: np.vstack([(np.sin([2 * np.pi * self.freqs[0] * ts]) + np.sin([2 * np.pi * self.freqs[1] * ts])), (np.sin([2 * np.pi * self.freqs[2] * ts]) + np.sin([2 * np.pi * self.freqs[3] * ts]))]) # Normalize, add noise X = self.X_fn(self.ts) self.X_mean = np.mean(X, axis=1).reshape(-1,1) self.X_std = np.std(X, axis=1).reshape(-1,1) X = (X - self.X_mean)/self.X_std self.X_true = np.copy(X) self.X = X + np.random.randn(*X.shape)*self.noise # Construct test vars self.ts_test = None self.X_test = None def run_test(self, tf_predict, npts_predict): \u0026quot;\u0026quot;\u0026quot; Parameters: tf_predict: final time npts_predict: number of points between 0 and tf_predict Updates: self.ts_test: test time series self.X_test_true: normalized ground truth for the test \u0026quot;\u0026quot;\u0026quot; self.ts_test = np.linspace(0, tf_predict, npts_predict) X_test = self.X_fn(self.ts_test) # Use training std_dev and mean self.X_test_true = (X_test - self.X_mean)/self.X_std  Run the Experiment We run the spectral dynamic mode decomposition algorithm to learn the frequencies of an operator generating our toy time-series data. Because of the nature of the algorithm, we can do this with very noisy data (Here, we set the standard deviation at 0.5 for mean-zero variance-one toy training data).\nFirst, we configure the model. Then we set up the algorithm and run the optimization. The optimization is performed using the Accelerated Proximal Gradient Descent Method, or AGPD. The reason is because we are imposing sparsity using a $\\ell_1$ norm\u0026ndash;that is, a LASSO-type optimization.\n1. Configure the model # Config # ====== np.random.seed(1) # Data params npts = 400 # number of time points tf = 8 # max time std_noise = .5 # set the amount of noise on the mean-0, variance-1 data predict_factor = 3 # prediction goes out to factor*T exper = toy_data(tf, npts, std_noise) # Algorithm params freq_dim = 24 # freq. for algo to try learning_rate = 1e-3 # LR = 1/beta from beta-smooth obj. bound (at least ideally--I'm just choosing a number here) reg_factor = 5 # regularization on sparsity # SVD parameters threshold_type = 'percent' # choose 'count' for number or 'percent' for s/max(s) \u0026gt; threshold threshold = 1e-1 # Plot toggle print_omega_updates = True def print_update(omg, title): if print_omega_updates: print('{} $\\omega$:\\t'.format(title), np.sort(np.round(omg[omg.astype(bool)], 3)))  2. Set up the algorithm \u0026amp; 3. Optimize # Algorithm # ========= # 1. Initialize omega = np.zeros(freq_dim)*2 print_update(omega, 'Initial') A = np.random.rand(exper.X.shape[0], freq_dim*2) obj_his = [] err_his = [] # 2. FFT to obtain the initial starting point for the optimization for ifreq in range(len(omega)): # - Construct the residual via the current frequencies res = residual_j(ifreq, exper.X, A, omega, exper.ts) # - Select the maximum fft frequency as the initial value omega[ifreq] = max_fft_update(res, exper.dt) # - Update A A = update_A(exper.X, omega, exper.ts, threshold, threshold_type) # 3. Perform proximal gradient descent from the initial point # - Construct optimization functions lam_cs = reg_factor*norm(A.T.dot(exper.X), np.inf) def f(w): return loss(exper.X, A, w.flatten(), exper.ts) def gradf(w): return grad_loss(exper.X, A, w.flatten(), exper.ts) def func_g(w): return lam_cs*np.linalg.norm(w, ord=1) def prox_g(w, t): res = [] r = t*lam_cs for wi in w.flatten(): if wi \u0026gt; r: res.append(wi-r) elif wi \u0026lt; -r: res.append(wi+r) else: res.append(0) return np.array(res) # - Optimization algorithm w, iobj_his, ierr_his, cond = optimizeWithAPGD(omega.reshape(1,-1), f, func_g, gradf, prox_g, (1/learning_rate)*npts, max_iter=5000, verbose=True) obj_his.append(iobj_his) err_his.append(ierr_his) omega = w print_update(omega, 'Final ') # 4. Final operator update A = update_A(exper.X, omega, exper.ts, threshold, threshold_type) print_update(np.array(exper.freqs), 'Expected')  Initial $\\omega$:\t[] Final $\\omega$:\t[0.494 0.743 1.991 2.99 ] Expected $\\omega$:\t[0.5 0.75 2. 3. ]  We printed out the frequencies (previous cell). In the next cell, we show the objective value and the gradient of the objective for the iterations of the optimization. The characteristic oscillations of an accelerated gradient descent are observed.\n# Plot # ==== # Inspect convergence results fig,axes = plt.subplots(2,1,figsize=[10,10]) ax = axes[0] ax.plot(iobj_his) ax.set_ylabel('Obj. value') ax.set_xlabel('Iterations') ax.set_yscale('log') ax = axes[1] ax.plot(ierr_his) ax.set_ylabel('Gradient magn.') ax.set_xlabel('Iterations') ax.set_yscale('log')     Result We see the training (top) and test (bottom) results for our two-dimensional multi-frequency dynamics.\nNotice the order of magnitude increase in the horizontal time axis on the bottom plot. On this plot, we observe that the solutions match the test simulations and are stable because of the model assumptions.\n# Make prediction exper.run_test(tf*predict_factor, 10*npts) # keep sample freq the same bigOmg_test = BigOmg(omega, exper.ts_test) X_pred = A@(bigOmg_test) # Plot data fig,axes = plt.subplots(1,2,figsize=[20,3]) fig.subplots_adjust(hspace=0.3, wspace=0.2) leg_params = {'loc': 'upper right', 'shadow': True, 'fancybox': True} ax = axes[0] ax.plot(exper.ts, exper.X_true[0], color=cmap(1), label='Simulation') ax.plot(exper.ts, exper.X[0], ls='', marker='+', color=cmap(0), label='Training Data') ax.set_xlabel('t') ax.set_ylabel('x') ax.legend(**leg_params) ax = axes[1] ax.plot(exper.ts, exper.X_true[1], color=cmap(3), label='Simulation') ax.plot(exper.ts, exper.X[1], ls='', marker='+', color=cmap(2), label='Training Data') ax.legend(**leg_params) ax.set_xlabel('t') ax.set_ylabel('y') ax.set_ylim([-3.5,3.5]) # Plot model fig,axes = plt.subplots(2,1,figsize=[20,5]) fig.subplots_adjust(hspace=0.3, wspace=0.2) leg_params = {'loc': 'upper right', 'shadow': True, 'fancybox': True} ax = axes[0] ax.plot(exper.ts_test, exper.X_test_true[0], color=cmap(1), label='Test Simulation') ax.plot(exper.ts_test, X_pred[0], ls='-', color=cmap(0), label='Model Prediction') ax.legend(**leg_params) ax.set_xlabel('t') ax.set_ylabel('x') ax = axes[1] ax.plot(exper.ts_test, exper.X_test_true[1], color=cmap(3), label='Test Simulation') ax.plot(exper.ts_test, X_pred[1], ls='-', color=cmap(2), label='Model Prediction') ax.legend(**leg_params) ax.set_xlabel('t') ax.set_ylabel('y') ax.set_ylim([-3.5,3.5])  (Click on the figures to zoom.)\nTraining data:   Test data:   ","date":1609718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1609718400,"objectID":"d4e38e92047a2c842def4d5644a548a9","permalink":"https://andgoldschmidt.github.io/posts/spectral_dmd/","publishdate":"2021-01-04T00:00:00Z","relpermalink":"/posts/spectral_dmd/","section":"posts","summary":"Exploring a method for long time-series forecasting.","tags":["Machine Learning"],"title":"Spectral dynamic mode decomposition","type":"posts"},{"authors":null,"categories":null,"content":"Derivative is an open-source project I started in 2019-2020 that turned into a collaboration with Markus Quade (Github, @Ohjeah) and Brian de Silva (Github, @briandesilva). It is a standalone suite of numerical differentiation methods for noisy time series data written in Python.\nThe goal is to provide some common numerical differentiation techniques that showcase improvements that can be made on finite differences when data is noisy. The package binds these common differentiation methods to a single easily implemented differentiation interface to encourage user adaptation.\nDerivative is a contribution to PySINDy\n           PySINDy is an open source Python package for the Sparse Identification of Nonlinear Dynamical systems (SINDy).\nAt some point, I\u0026rsquo;ll write a post about my version of total variational regularization (see the figure above). I adapted a technique from The solution path of the generalized lasso (DOI: 10.1214/11-AOS878) by R.J. Tibshirani \u0026amp; J. Taylor to write a nice variation of the classic algorithm in Numerical Differentiation of Noisy, Nonsmooth Data (DOI: 10.5402/2011/164564) by Rick Chartrand.\n","date":1602028800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602028800,"objectID":"5098340af90564f460faa2e304a330c9","permalink":"https://andgoldschmidt.github.io/posts/derivative/","publishdate":"2020-10-07T00:00:00Z","relpermalink":"/posts/derivative/","section":"posts","summary":"Open-source Python code for numerical differentiation of noisy time series data.","tags":["Machine Learning"],"title":"Better numerical derivatives for data","type":"posts"},{"authors":null,"categories":null,"content":"Pyprotoclust is an implementatin of representative hierarchical clustering using minimax linkage. The original algorithm is from Hierarchical Clustering With Prototypes via Minimax Linkage (DOI: 10.1198/jasa.2011.tm10183) by J. Bien and R. Tibshirani; Pyprotoclust takes a distance matrix as input. It returns a linkage matrix encoding the hierachical clustering as well as an additional list labelling the prototypes associated with each clustering.\nI coded up a fun example inspired by the original paper where I apply the algorithm to determine representative pictures for the Olivetti Faces dataset. It can be found in the Pyprotoclust documentation.\nFigure: (Left) A dendrogram of the hierarchical clustering example with a dashed line at the example cut height. (Right) A scatter plot of the example with circles centered at prototypes drawn with radii equal to the top-level linkage heights of each cluster.\n","date":1595721600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1595721600,"objectID":"72dfe0083482e799faed552ad01a267c","permalink":"https://andgoldschmidt.github.io/posts/pyprotoclust/","publishdate":"2020-07-26T00:00:00Z","relpermalink":"/posts/pyprotoclust/","section":"posts","summary":"An open-source Cython implementation of representative hierarchical clustering using minimax linkage.","tags":["Machine Learning"],"title":"Hierarchical clustering with prototypes","type":"posts"},{"authors":null,"categories":null,"content":"There are lots of features that go into packaging up Python code for other users. How can we make a project that ships easily to users and takes advantage of our normal development tools? We\u0026rsquo;ll discuss:\n Poetry: for easily making and publishing a package Sphinx: for making documentation Readthedocs: free professional-looking documenation hosting and formatting PyCharm: the default Python IDE (you can get the professional version as a student) PyPI: Python pacakge index, where you store stuff that people can pip install.  Basics Read the Poetry docs to install. It\u0026rsquo;s good documentation; you should skim the Installation and Basic Usage first. For zsh users, make sure Poetry got added to your Path inside zshrc. For bash people, it\u0026rsquo;s automatic.\nLet\u0026rsquo;s make a new project with Poetry.\n Create a python project. (See Choosing a project name below this list.) poetry new myproject  Change to this directory.\n Start the poetry virtual environment. poetry shell  This will make a virtual environment that is like a fresh Python installation for us to be explicit about our package\u0026rsquo;s dependencies.\n Install new pacakges as needed. poetry add python_package  The name python_pacakge would be something like numpy. Poetry will install the package to the virtual environment and add the package to the pyproject.toml file.\n Take a look at the pyproject.toml file. All your package settings are here. Any added pacakges appear automatically. We also have a file not for human consumption called poetry.lock which does all the work of building the exact environement we are using. It can be good to commit this poetry.lock to version control so someone interacting with our package knows the exact packages we were using. To update all pacakges added with poetry add, run poetry update. To install the current system and update the poetry.lock file, run poetry install.  Choosing a project name A new poetry project ``myproject'' has a specific directory structure:\n myproject |-- pyproject.toml |-- README.rst |-- myproject | |-- __init__.py |-- tests |-- __init__.py |-- test_myproject.py  The project name is for the top level directory of the project. This is the name of the github repository and the PyPI project so it is invoked with pip install myprojectname. It should be unique. Project names on PyPI should NOT use dashes (https://stackoverflow.com/questions/8350853/). Underscores are allowed but discouraged. The package or module name is the inner directory containing __init__.py. This is the code that will be invoked by the user as import my_project_name in code. It does not have to be unique. It can use underscores.Note that Poetry defaults to matching project and package names. This is also the Python style guideline (PEP 423).\nVersion control Now we start tracking our new package on version control. Init a git repo in the project directory. Do this in your usual way. (e.g. hosting on github). The splash page for your package will be README.rst! Make it pretty.\nPyCharm Let\u0026rsquo;s use a modern IDE. Open up the project in PyCharm.\n  Get the location of the interpreter for this virtual environment for PyCharm. Run this command:\npoetry run which python    Make the virtual environment default for PyCharm.\n Settings $\\rightarrow$ Project $\\rightarrow$ Python Interpreter Click the gear, and select add. Choose the option \\textit{existing environment} and add the path to the poetry virtual environment. Apply changes.  Now PyCharm will complain when you try to use python code you haven\u0026rsquo;t added. PyCharm will also give you actions to import missing libraries. However, be sure to add the python libraries with poetry, not PyCharm.\n  Add documentation with Sphinx Let\u0026rsquo;s set up Sphinx.\n  Start\nmkdir docs poetry add sphinx cd docs sphinx-quickstart  The command line will prompt you with a few questions. Use the default settings, but enter any project-specific information as needed.\n  All Sphinx settings are in conf.py. The first setting to edit is the path. Uncomment the lines:\nimport os import sys sys.path.insert(0, os.path.abspath('.'))  and change the \u0026ldquo;.\u0026rdquo; to \u0026ldquo;..\u0026rdquo; to reflect the docs folder.\n  Make sure that Sphinx knows that the main file is index.rst by adding the lines\n# Assign the master document master_doc = 'index'  to conf.py.\n  Test to see that your docs compile. Run the command\nmake html  inside the docs folder then open up index.html in your web browser.\n  Add docs to readthedocs.\n Go to readthedocs, login, then find and click import. Paste the link to the github repo and create.  Readthedocs will find the conf.py file and build the documentation.\nCheck that github will let readthedocs know when the documentation is updated. Go to the project repo settings and confirm that the Webhooks tab includes readthedocs.    Note: Oddly, the default Poetry config section tool.poetry.dependencies that allows users of your package to avoid installing development tools like Sphinx is not supported by readthedocs (the listed packages won\u0026rsquo;t be used). There is an alternative, e.g.\nsphinx = {version=\u0026quot;^3.0.2\u0026quot;, optional = true}  To add packages to Poetry as optional you can call poetry add sphinx \u0026ndash;optional to autofill this format. In your .readthedocs.yaml file, you can make sure these packages are installed by adding the extra_name parameter to extra_requirements, e.g.:\npython: version: 3.7 install: - method: pip path: . extra_requirements: - docs  Publish the package on PyPI This is as easy as poetry publish! First, we\u0026rsquo;ll have to setup our PyPI whic we can do by following the Poetry documentation.\nAdditional tasks Sphinx can automatically generate documentation for the modules, classes, and functions that have properly formatted docstrings. There are two main docstring styles: NumPy and Google. I use Google\u0026rsquo;s docstring format becaues it takes up less vertical space. The essential Sphinx extensions are autodoc (for automatically making docstrings into reStructuredText) and napoleon (for docstring formats). Both should be added to the Sphinx conf.py file as extensions,\nextensions = ['sphinx.ext.autodoc','sphinx.ext.napoleon']  No installation by Poetry is necessary because both are part of the base installation of Sphinx.\nA common point of troubleshooting is that the readthedocs servers do not have your desired library installed. You will need to go to Advanced Settings on readthedocs and make sure you select to use both\nInstall Project Install your project inside a venv using setup.py install Use system packages Give the venv access to the global site packages dir  Technically, you may only need the second option to get e.g. numpy which readthedocs has installed on their servers for you. But if you want a more advanced option like sklearn that isn\u0026rsquo;t on the default servers, you\u0026rsquo;ll need to install the project. This means you need one more file at the top level of your project called .readthedocs.yaml which looks something like\nversion: 2 build: image: latest python: version: 3.7 install: - method: pip path: . extra_requirements: - docs sphinx: configuration: docs/conf.py  This file makes sure that the setup.py command (the old package tool) interacts with the poetry configuration files correctly. Currently, there are some changes to python standards moving in poetry\u0026rsquo;s direction, but these are not implemented in readthedocs yet. Hence, this extra file.\nAdding Jupyter notebooks to the docs The key tool here is nbsphinx. This will need to be installed by poetry. Also, an ipython kernel and a jupyter reader will need to be installed for readthedocs to run the notebook (explicitely, poetry add ipykernel and poetry add jupyter_client. You can make these optional. You will also need the .readthedocs.yaml file so see the note at the end of the autodoc section.\nAdding a LICENSE  Create a file in docs called license.rst and give the file a header like  License ======= ...  Inside the index.rst look for  .. toctree:: :maxdepth: 2 :caption: Contents: license  where we have added license to link the license file to the main documentation page (the name of the link will reflect the headings/subheadings in the file license.rst).\nCython Development I think the most effective cython tutorial is this cython documentation example. You\u0026rsquo;ll eventually be introduced to the very basic example:\nfrom setuptools import setup from Cython.Build import cythonize setup(ext_modules=cythonize(\u0026quot;rect.pyx\u0026quot;))  This example is good because it shows the essential features. However, if you have multiple c++ files that you want to compile together, you will need more. Eventually you\u0026rsquo;ll want to create more complicated objects to pass to cythonize/ext_modules. This will introduce you to distutils.\nThe main change to have cython code is to add a build.py file. This file uses the python library distutils to link all the c++ files and call cython. I have an example build.py on my Github. To get Poetry to use your build.py, you need to include {build = 'build.py'} under the [tool.poetry] section in your pyproject.toml.\nFor readthedocs, it seems that a wrapper around this build.py script is needed. A short setup.py script can be written to do this. You might want to look at additional tasks for some context on parts of this, but here\u0026rsquo;s an example:\n# Wrapper over build.py for readthedocs from distutils.core import setup from build import build global setup_kwargs setup_kwargs = {} build(setup_kwargs) setup(**setup_kwargs)  Another issue to address with readthedocs is making sure autodoc works for cython code. This fix is courtesy of https://stackoverflow.com/questions/13238736.\nUsing Docker The goal of this section is to build and distribute a C++ shared package called example_package inside a Python wheel using poetry and auditwheel. For this, I followed: https://github.com/riddell-stan/poetry-install-shared-lib-demo.\nThe wheel created using these instructions conforms to the manylinux2014 standard and should be usable on most Linux systems. This README also includes notes which may be of interest to developers seeking to understand how the auditwheel repair command works. You\u0026rsquo;ll need to install docker (so we can use PyPA\u0026rsquo;s manylinux2014 build image).\n","date":1589587200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1589587200,"objectID":"cd42a50ffc0b869ace2d37227bb9bb25","permalink":"https://andgoldschmidt.github.io/posts/poetry/","publishdate":"2020-05-16T00:00:00Z","relpermalink":"/posts/poetry/","section":"posts","summary":"A post on how to make Python packages with Poetry.","tags":["Posts"],"title":"Python package development","type":"posts"},{"authors":null,"categories":null,"content":"In this project on Github I coded up some tutorial concepts in control theory like observability, controllability, and the linear quadratic regulator using the example environment of a linear pendulum fixed to a cart. I also made fun Jupyter notebook movies to visualize the results.\nAlso included under this project are the slides I did for a short class project covering reinforcement learning (RL) for CartPole from the OpenAI lab. It\u0026rsquo;s nice to contextualize model-free RL methods for control within a familiar environment where we have covered the control theory basics.\nTODO: Turn this into a Google Colab https://colab.research.google.com/ Embedding the notebook as a static webpage means there\u0026rsquo;s not a lot of fun to have with the movies so come back soon for a dynamic version of this post.\n","date":1575849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1575849600,"objectID":"ce32f5e9af8318bf54e84175ab872206","permalink":"https://andgoldschmidt.github.io/posts/cartpole/","publishdate":"2019-12-09T00:00:00Z","relpermalink":"/posts/cartpole/","section":"posts","summary":"Control theory basics using a rigid pendulum fixed to a cart.","tags":["Control","Machine learning"],"title":"Control basics with CartPole","type":"posts"},{"authors":null,"categories":null,"content":"","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f26b5133c34eec1aa0a09390a36c2ade","permalink":"https://andgoldschmidt.github.io/admin/config.yml","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/admin/config.yml","section":"","summary":"","tags":null,"title":"","type":"wowchemycms"}]